{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultinomialNBClassifier import multinomial_nb_classifier\n",
    "from NBClassifier import nb_classifier\n",
    "from LogisticRegressionClassifer import lr_classifer\n",
    "from SGDClassifier import sgd_classifier\n",
    "from Parser import get_vocabulary, bag_of_words, bernoulli\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(v):\n",
    "    return f\"{v*100:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row(name, data_mode, table, res_arr, hyper_param=\"\"):\n",
    "    accuracy, precision, recall, f1 = res_arr\n",
    "    table.add_row([name, data_mode, percent(accuracy), percent(precision), percent(recall), percent(f1), hyper_param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------+\n",
      "|                                                  dataset1                                                  |\n",
      "+------------+--------------+----------+-----------+--------+--------+---------------------------------------+\n",
      "| classifier |  data mode   | accuracy | precision | recall |   f1   |            hyper-parameter            |\n",
      "+------------+--------------+----------+-----------+--------+--------+---------------------------------------+\n",
      "|     nb     |  bernoulli   |  76.36%  |  100.00%  | 13.08% | 23.13% |                                       |\n",
      "|    mnb     | bag_of_words |  94.14%  |   93.22%  | 84.62% | 88.71% |                                       |\n",
      "|     lr     | bag_of_words |  93.93%  |   87.97%  | 90.00% | 88.97% |               alpha:0.5               |\n",
      "|     lr     |  bernoulli   |  96.23%  |   93.08%  | 93.08% | 93.08% |               alpha:0.25              |\n",
      "|    sgd     | bag_of_words |  91.63%  |   86.89%  | 81.54% | 84.13% |  max_iter:100, alpha:0.1, penalty:l2  |\n",
      "|    sgd     |  bernoulli   |  96.03%  |   95.12%  | 90.00% | 92.49% | max_iter:1000, alpha:0.01, penalty:l2 |\n",
      "+------------+--------------+----------+-----------+--------+--------+---------------------------------------+\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|                                                   dataset2                                                  |\n",
      "+------------+--------------+----------+-----------+---------+--------+---------------------------------------+\n",
      "| classifier |  data mode   | accuracy | precision |  recall |   f1   |            hyper-parameter            |\n",
      "+------------+--------------+----------+-----------+---------+--------+---------------------------------------+\n",
      "|     nb     |  bernoulli   |  87.85%  |   85.56%  | 100.00% | 92.22% |                                       |\n",
      "|    mnb     | bag_of_words |  94.48%  |   94.79%  |  97.70% | 96.22% |                                       |\n",
      "|     lr     | bag_of_words |  97.05%  |   96.30%  |  99.74% | 97.99% |               alpha:0.1               |\n",
      "|     lr     |  bernoulli   |  96.87%  |   95.83%  | 100.00% | 97.87% |               alpha:0.1               |\n",
      "|    sgd     | bag_of_words |  95.03%  |   95.73%  |  97.44% | 96.58% |  max_iter:100, alpha:0.01, penalty:l2 |\n",
      "|    sgd     |  bernoulli   |  97.24%  |   96.31%  | 100.00% | 98.12% | max_iter:2500, alpha:0.01, penalty:l2 |\n",
      "+------------+--------------+----------+-----------+---------+--------+---------------------------------------+\n",
      "+-----------------------------------------------------------------------------------------------------------+\n",
      "|                                                  dataset3                                                 |\n",
      "+------------+--------------+----------+-----------+--------+--------+--------------------------------------+\n",
      "| classifier |  data mode   | accuracy | precision | recall |   f1   |           hyper-parameter            |\n",
      "+------------+--------------+----------+-----------+--------+--------+--------------------------------------+\n",
      "|     nb     |  bernoulli   |  71.49%  |  100.00%  | 12.75% | 22.62% |                                      |\n",
      "|    mnb     | bag_of_words |  93.86%  |   94.81%  | 85.91% | 90.14% |                                      |\n",
      "|     lr     | bag_of_words |  93.86%  |   89.54%  | 91.95% | 90.73% |              alpha:0.5               |\n",
      "|     lr     |  bernoulli   |  95.39%  |   91.56%  | 94.63% | 93.07% |              alpha:0.5               |\n",
      "|    sgd     | bag_of_words |  94.08%  |   90.13%  | 91.95% | 91.03% | max_iter:2500, alpha:0.1, penalty:l2 |\n",
      "|    sgd     |  bernoulli   |  95.39%  |   91.03%  | 95.30% | 93.11% | max_iter:100, alpha:0.01, penalty:l2 |\n",
      "+------------+--------------+----------+-----------+--------+--------+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "np.warnings.filterwarnings(\"ignore\", \"overflow\")\n",
    "nb = nb_classifier()\n",
    "mnb = multinomial_nb_classifier()\n",
    "lr = lr_classifer()\n",
    "sgd = sgd_classifier()\n",
    "for i in range(1, 4):\n",
    "    table = PrettyTable(['classifier', 'data mode', 'accuracy', 'precision', 'recall', 'f1', 'hyper-parameter'])\n",
    "    table.title = f\"dataset{i}\"\n",
    "    vocabulary = get_vocabulary(f\"dataset{i}/train\")\n",
    "    bow_train_data, bow_train_classes = bag_of_words(f\"dataset{i}/train\", vocabulary)\n",
    "    bow_test_data, bow_test_classes = bag_of_words(f\"dataset{i}/test\", vocabulary)\n",
    "    bnl_train_data, bnl_train_classes = bernoulli(f\"dataset{i}/train\", vocabulary)\n",
    "    bnl_test_data, bnl_test_classes = bernoulli(f\"dataset{i}/test\", vocabulary)\n",
    "    #nb\n",
    "    nb.train(bnl_train_data, bnl_train_classes)\n",
    "    add_row(\"nb\", \"bernoulli\", table, nb.test(bnl_test_data, bnl_test_classes))\n",
    "    #mnb\n",
    "    mnb.train(bow_train_data, bow_train_classes)\n",
    "    add_row(\"mnb\", \"bag_of_words\", table, mnb.test(bow_test_data, bow_test_classes))\n",
    "    #lr\n",
    "    l = lr.train(bow_train_data, bow_train_classes)\n",
    "    add_row(\"lr\", \"bag_of_words\", table, lr.test(bow_test_data, bow_test_classes), f\"alpha:{l}\")\n",
    "    l = lr.train(bnl_train_data, bnl_train_classes)\n",
    "    add_row(\"lr\", \"bernoulli\", table, lr.test(bnl_test_data, bnl_test_classes), f\"alpha:{l}\")\n",
    "    #sgd\n",
    "    hyper_param = sgd.train(bow_train_data, bow_train_classes)\n",
    "    add_row(\"sgd\", \"bag_of_words\", table, sgd.test(bow_test_data, bow_test_classes), hyper_param)\n",
    "    hyper_param = sgd.train(bnl_train_data, bnl_train_classes)\n",
    "    add_row(\"sgd\", \"bernoulli\", table, sgd.test(bnl_test_data, bnl_test_classes), hyper_param)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
